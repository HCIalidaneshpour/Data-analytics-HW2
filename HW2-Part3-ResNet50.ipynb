{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet50 برای تشخیص تومور مغزی"
      ],
      "metadata": {
        "id": "jGkJVPpXp_cG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  وارد کردن کتابخانه‌ها"
      ],
      "metadata": {
        "id": "lHYlpaZGqH7K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuaKwzYWkaJg",
        "outputId": "672d482b-9f6e-4cfd-f41e-eab0fe0bbdb9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m615.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q albumentations\n",
        "!pip install -q tensorflow\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import albumentations as A"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  دانلود دیتاست"
      ],
      "metadata": {
        "id": "4ltNcAgzqJ_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n"
      ],
      "metadata": {
        "id": "41Si_-UbkeYl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://github.com/ultralytics/assets/releases/download/v0.0.0/brain-tumor.zip\"\n",
        "dataset_zip = \"brain-tumor.zip\"\n",
        "dataset_dir = \"brain_tumor_data\"\n",
        "\n",
        "if not os.path.exists(dataset_zip):\n",
        "    !wget -O {dataset_zip} {dataset_url}\n",
        "if not os.path.exists(dataset_dir):\n",
        "    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(dataset_dir)\n",
        "\n",
        "filepaths, labels = [], []\n",
        "for subset in ['train', 'valid']:\n",
        "    img_dir = os.path.join(dataset_dir, subset, \"images\")\n",
        "    lbl_dir = os.path.join(dataset_dir, subset, \"labels\")\n",
        "    for fname in os.listdir(img_dir):\n",
        "        if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            fpath = os.path.join(img_dir, fname)\n",
        "            lpath = os.path.join(lbl_dir, os.path.splitext(fname)[0] + \".txt\")\n",
        "            label = 'no'\n",
        "            if os.path.exists(lpath):\n",
        "                with open(lpath) as f:\n",
        "                    if '1' in [line.split()[0] for line in f.readlines()]:\n",
        "                        label = 'yes'\n",
        "            filepaths.append(fpath)\n",
        "            labels.append(label)\n",
        "\n",
        "df = pd.DataFrame({'filename': filepaths, 'label': labels})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR6F4l71kg72",
        "outputId": "8716c82b-0d89-47e8-804a-fa07dad8b6dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-26 21:57:26--  https://github.com/ultralytics/assets/releases/download/v0.0.0/brain-tumor.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/f35ed844-7b00-438a-a4dd-23eacabcd966?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250526%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250526T215726Z&X-Amz-Expires=300&X-Amz-Signature=d84ede41fbac48d482151ffadf038ddef0b4ce903a35665159b8517e39f25395&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dbrain-tumor.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-05-26 21:57:26--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/f35ed844-7b00-438a-a4dd-23eacabcd966?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250526%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250526T215726Z&X-Amz-Expires=300&X-Amz-Signature=d84ede41fbac48d482151ffadf038ddef0b4ce903a35665159b8517e39f25395&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dbrain-tumor.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4439988 (4.2M) [application/octet-stream]\n",
            "Saving to: ‘brain-tumor.zip’\n",
            "\n",
            "brain-tumor.zip     100%[===================>]   4.23M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-05-26 21:57:26 (50.8 MB/s) - ‘brain-tumor.zip’ saved [4439988/4439988]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## تقسیم داده ها"
      ],
      "metadata": {
        "id": "F4UOLlJ4qVZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)"
      ],
      "metadata": {
        "id": "jeSZewnwklMY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation و پردازش تصویر"
      ],
      "metadata": {
        "id": "bUK-8XM-qdfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_aug = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE)\n",
        "])\n",
        "\n",
        "val_aug = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE)\n",
        "])\n"
      ],
      "metadata": {
        "id": "jt98sMj8lmoq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_train_image(filename, label):\n",
        "    filename = filename.numpy().decode('utf-8')\n",
        "    label = label.numpy()\n",
        "    image = cv2.imread(filename)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = train_aug(image=image)['image']\n",
        "    image = preprocess_input(image.astype(np.float32))\n",
        "    return image, label\n",
        "\n",
        "def preprocess_val_image(filename, label):\n",
        "    filename = filename.numpy().decode('utf-8')\n",
        "    label = label.numpy()\n",
        "    image = cv2.imread(filename)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = val_aug(image=image)['image']\n",
        "    image = preprocess_input(image.astype(np.float32))\n",
        "    return image, label\n",
        "\n",
        "def tf_preprocess_train(filename, label):\n",
        "    image, label = tf.py_function(preprocess_train_image, [filename, label], [tf.float32, tf.float32])\n",
        "    image.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
        "    label.set_shape([])\n",
        "    return image, label\n",
        "\n",
        "def tf_preprocess_val(filename, label):\n",
        "    image, label = tf.py_function(preprocess_val_image, [filename, label], [tf.float32, tf.float32])\n",
        "    image.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
        "    label.set_shape([])\n",
        "    return image, label\n"
      ],
      "metadata": {
        "id": "pkOhMrgekyz_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ساخت Dataset"
      ],
      "metadata": {
        "id": "9BgY9DhWqiSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataframe_to_dataset(df, batch_size, preprocess_fn, shuffle=True):\n",
        "    X = df['filename'].values\n",
        "    y = df['label'].apply(lambda x: 1 if x=='yes' else 0).values\n",
        "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(df))\n",
        "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train_ds = dataframe_to_dataset(train_df, BATCH_SIZE, tf_preprocess_train, shuffle=True)\n",
        "val_ds = dataframe_to_dataset(val_df, BATCH_SIZE, tf_preprocess_val, shuffle=False)\n",
        "test_ds = dataframe_to_dataset(test_df, 1, tf_preprocess_val, shuffle=False)\n"
      ],
      "metadata": {
        "id": "NV1pUjrUk4K0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class Weights"
      ],
      "metadata": {
        "id": "NLTmw8xVqkEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = compute_class_weight('balanced', classes=np.unique(train_df['label'].map({'no':0, 'yes':1})),\n",
        "                               y=train_df['label'].map({'no':0, 'yes':1}))\n",
        "class_weights = {i: w for i, w in enumerate(weights)}\n"
      ],
      "metadata": {
        "id": "Y89_WjzXk8vJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ساخت مدل"
      ],
      "metadata": {
        "id": "JJ9kU76iqsa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssUag7-6k-5t",
        "outputId": "58c73d8d-69d4-468a-fadc-250b19812446"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## کال‌بک‌ها"
      ],
      "metadata": {
        "id": "zLgisQYkq1KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_cb = ModelCheckpoint(\"best_resnet50.h5\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "early_cb = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
        "reduce_lr_cb = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, verbose=1)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "MSaylS-DlCzo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  آموزش اولیه مدل\n"
      ],
      "metadata": {
        "id": "cz6NP5ceq9w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=30,\n",
        "    callbacks=[checkpoint_cb, early_cb, reduce_lr_cb],\n",
        "    class_weight=class_weights\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP9NbO0elGUS",
        "outputId": "0e1855b8-8721-454c-dbfb-3a70fda42c13"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - accuracy: 0.5331 - loss: 0.8803\n",
            "Epoch 1: val_accuracy improved from -inf to 0.61078, saving model to best_resnet50.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 666ms/step - accuracy: 0.5329 - loss: 0.8811 - val_accuracy: 0.6108 - val_loss: 0.6798 - learning_rate: 1.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - accuracy: 0.6065 - loss: 0.7608\n",
            "Epoch 2: val_accuracy did not improve from 0.61078\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 536ms/step - accuracy: 0.6067 - loss: 0.7600 - val_accuracy: 0.5868 - val_loss: 0.7088 - learning_rate: 1.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - accuracy: 0.6316 - loss: 0.6867\n",
            "Epoch 3: val_accuracy did not improve from 0.61078\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 531ms/step - accuracy: 0.6318 - loss: 0.6863 - val_accuracy: 0.6108 - val_loss: 0.6833 - learning_rate: 1.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - accuracy: 0.7083 - loss: 0.6242\n",
            "Epoch 4: val_accuracy did not improve from 0.61078\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 536ms/step - accuracy: 0.7079 - loss: 0.6242 - val_accuracy: 0.5988 - val_loss: 0.6941 - learning_rate: 1.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - accuracy: 0.6893 - loss: 0.5907\n",
            "Epoch 5: val_accuracy improved from 0.61078 to 0.61677, saving model to best_resnet50.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 552ms/step - accuracy: 0.6900 - loss: 0.5899 - val_accuracy: 0.6168 - val_loss: 0.6640 - learning_rate: 1.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - accuracy: 0.7521 - loss: 0.4904\n",
            "Epoch 6: val_accuracy improved from 0.61677 to 0.62874, saving model to best_resnet50.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 568ms/step - accuracy: 0.7520 - loss: 0.4910 - val_accuracy: 0.6287 - val_loss: 0.6420 - learning_rate: 1.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - accuracy: 0.7555 - loss: 0.5159\n",
            "Epoch 7: val_accuracy improved from 0.62874 to 0.70060, saving model to best_resnet50.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 561ms/step - accuracy: 0.7551 - loss: 0.5160 - val_accuracy: 0.7006 - val_loss: 0.5963 - learning_rate: 1.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - accuracy: 0.7355 - loss: 0.5486\n",
            "Epoch 8: val_accuracy did not improve from 0.70060\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 542ms/step - accuracy: 0.7363 - loss: 0.5477 - val_accuracy: 0.6886 - val_loss: 0.5796 - learning_rate: 1.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - accuracy: 0.8009 - loss: 0.4556\n",
            "Epoch 9: val_accuracy improved from 0.70060 to 0.71257, saving model to best_resnet50.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 558ms/step - accuracy: 0.8007 - loss: 0.4555 - val_accuracy: 0.7126 - val_loss: 0.5639 - learning_rate: 1.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - accuracy: 0.7941 - loss: 0.4564\n",
            "Epoch 10: val_accuracy improved from 0.71257 to 0.74251, saving model to best_resnet50.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 548ms/step - accuracy: 0.7940 - loss: 0.4562 - val_accuracy: 0.7425 - val_loss: 0.5451 - learning_rate: 1.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - accuracy: 0.8212 - loss: 0.4280\n",
            "Epoch 11: val_accuracy did not improve from 0.74251\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 536ms/step - accuracy: 0.8203 - loss: 0.4288 - val_accuracy: 0.7425 - val_loss: 0.5440 - learning_rate: 1.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - accuracy: 0.8114 - loss: 0.4011\n",
            "Epoch 12: val_accuracy improved from 0.74251 to 0.76048, saving model to best_resnet50.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 550ms/step - accuracy: 0.8112 - loss: 0.4015 - val_accuracy: 0.7605 - val_loss: 0.5285 - learning_rate: 1.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - accuracy: 0.7864 - loss: 0.4338\n",
            "Epoch 13: val_accuracy improved from 0.76048 to 0.77844, saving model to best_resnet50.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 556ms/step - accuracy: 0.7874 - loss: 0.4323 - val_accuracy: 0.7784 - val_loss: 0.5146 - learning_rate: 1.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - accuracy: 0.8382 - loss: 0.3800\n",
            "Epoch 14: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 542ms/step - accuracy: 0.8376 - loss: 0.3803 - val_accuracy: 0.7665 - val_loss: 0.5197 - learning_rate: 1.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - accuracy: 0.8413 - loss: 0.3824\n",
            "Epoch 15: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 537ms/step - accuracy: 0.8412 - loss: 0.3821 - val_accuracy: 0.7545 - val_loss: 0.5162 - learning_rate: 1.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - accuracy: 0.8820 - loss: 0.3245\n",
            "Epoch 16: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 547ms/step - accuracy: 0.8809 - loss: 0.3254 - val_accuracy: 0.7365 - val_loss: 0.5139 - learning_rate: 1.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - accuracy: 0.8801 - loss: 0.3182\n",
            "Epoch 17: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 538ms/step - accuracy: 0.8797 - loss: 0.3185 - val_accuracy: 0.7665 - val_loss: 0.5135 - learning_rate: 1.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - accuracy: 0.8487 - loss: 0.3464\n",
            "Epoch 18: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 541ms/step - accuracy: 0.8493 - loss: 0.3453 - val_accuracy: 0.7665 - val_loss: 0.4983 - learning_rate: 1.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - accuracy: 0.8560 - loss: 0.3250\n",
            "Epoch 19: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 539ms/step - accuracy: 0.8557 - loss: 0.3258 - val_accuracy: 0.7545 - val_loss: 0.4936 - learning_rate: 1.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - accuracy: 0.8399 - loss: 0.3285\n",
            "Epoch 20: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 535ms/step - accuracy: 0.8404 - loss: 0.3283 - val_accuracy: 0.7545 - val_loss: 0.4941 - learning_rate: 1.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - accuracy: 0.8600 - loss: 0.3249\n",
            "Epoch 21: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 537ms/step - accuracy: 0.8602 - loss: 0.3241 - val_accuracy: 0.7605 - val_loss: 0.5190 - learning_rate: 1.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - accuracy: 0.8679 - loss: 0.2885\n",
            "Epoch 22: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 544ms/step - accuracy: 0.8671 - loss: 0.2898 - val_accuracy: 0.7365 - val_loss: 0.5212 - learning_rate: 1.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - accuracy: 0.8892 - loss: 0.2769\n",
            "Epoch 23: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 543ms/step - accuracy: 0.8891 - loss: 0.2773 - val_accuracy: 0.7725 - val_loss: 0.5034 - learning_rate: 1.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - accuracy: 0.8731 - loss: 0.3155\n",
            "Epoch 24: val_accuracy did not improve from 0.77844\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 549ms/step - accuracy: 0.8729 - loss: 0.3153 - val_accuracy: 0.7665 - val_loss: 0.5040 - learning_rate: 1.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - accuracy: 0.8867 - loss: 0.2836\n",
            "Epoch 25: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 540ms/step - accuracy: 0.8865 - loss: 0.2837 - val_accuracy: 0.7605 - val_loss: 0.4961 - learning_rate: 5.0000e-05\n",
            "Epoch 26/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - accuracy: 0.8825 - loss: 0.2754\n",
            "Epoch 26: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 540ms/step - accuracy: 0.8829 - loss: 0.2750 - val_accuracy: 0.7485 - val_loss: 0.4990 - learning_rate: 5.0000e-05\n",
            "Epoch 27/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 0.8935 - loss: 0.2562\n",
            "Epoch 27: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 533ms/step - accuracy: 0.8930 - loss: 0.2572 - val_accuracy: 0.7485 - val_loss: 0.5032 - learning_rate: 5.0000e-05\n",
            "Epoch 28/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - accuracy: 0.8991 - loss: 0.2575\n",
            "Epoch 28: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 536ms/step - accuracy: 0.8990 - loss: 0.2574 - val_accuracy: 0.7365 - val_loss: 0.5062 - learning_rate: 5.0000e-05\n",
            "Epoch 29/30\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - accuracy: 0.8871 - loss: 0.2621\n",
            "Epoch 29: val_accuracy did not improve from 0.77844\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 548ms/step - accuracy: 0.8873 - loss: 0.2617 - val_accuracy: 0.7784 - val_loss: 0.4972 - learning_rate: 5.0000e-05\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 19.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79fdc024a050>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## فاین‌تیونینگ"
      ],
      "metadata": {
        "id": "IdL5W1xxrFm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-30]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "OSZ5pgq-lNn_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=40,\n",
        "    callbacks=[checkpoint_cb, early_cb, reduce_lr_cb],\n",
        "    class_weight=class_weights\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRQfkrvYlXTO",
        "outputId": "5982cf23-a1f7-4956-a4d5-c83213c8aa0f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646ms/step - accuracy: 0.7649 - loss: 0.5298\n",
            "Epoch 1: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 862ms/step - accuracy: 0.7647 - loss: 0.5300 - val_accuracy: 0.7725 - val_loss: 0.5115 - learning_rate: 1.0000e-05\n",
            "Epoch 2/40\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648ms/step - accuracy: 0.7817 - loss: 0.4758\n",
            "Epoch 2: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 750ms/step - accuracy: 0.7816 - loss: 0.4753 - val_accuracy: 0.7605 - val_loss: 0.5137 - learning_rate: 1.0000e-05\n",
            "Epoch 3/40\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step - accuracy: 0.8410 - loss: 0.3417\n",
            "Epoch 3: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 745ms/step - accuracy: 0.8412 - loss: 0.3416 - val_accuracy: 0.7665 - val_loss: 0.5279 - learning_rate: 1.0000e-05\n",
            "Epoch 4/40\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641ms/step - accuracy: 0.8569 - loss: 0.3302\n",
            "Epoch 4: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 743ms/step - accuracy: 0.8571 - loss: 0.3302 - val_accuracy: 0.7725 - val_loss: 0.5356 - learning_rate: 1.0000e-05\n",
            "Epoch 5/40\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648ms/step - accuracy: 0.8984 - loss: 0.2718\n",
            "Epoch 5: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 751ms/step - accuracy: 0.8981 - loss: 0.2722 - val_accuracy: 0.7605 - val_loss: 0.5364 - learning_rate: 1.0000e-05\n",
            "Epoch 6/40\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642ms/step - accuracy: 0.9315 - loss: 0.2061\n",
            "Epoch 6: val_accuracy did not improve from 0.77844\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 742ms/step - accuracy: 0.9314 - loss: 0.2063 - val_accuracy: 0.7725 - val_loss: 0.5381 - learning_rate: 1.0000e-05\n",
            "Epoch 7/40\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640ms/step - accuracy: 0.9279 - loss: 0.2114\n",
            "Epoch 7: val_accuracy did not improve from 0.77844\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 741ms/step - accuracy: 0.9274 - loss: 0.2121 - val_accuracy: 0.7725 - val_loss: 0.5341 - learning_rate: 5.0000e-06\n",
            "Epoch 8/40\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647ms/step - accuracy: 0.9249 - loss: 0.2063\n",
            "Epoch 8: val_accuracy improved from 0.77844 to 0.79042, saving model to best_resnet50.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 774ms/step - accuracy: 0.9243 - loss: 0.2073 - val_accuracy: 0.7904 - val_loss: 0.5300 - learning_rate: 5.0000e-06\n",
            "Epoch 9/40\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638ms/step - accuracy: 0.9337 - loss: 0.1850\n",
            "Epoch 9: val_accuracy improved from 0.79042 to 0.79641, saving model to best_resnet50.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 766ms/step - accuracy: 0.9335 - loss: 0.1851 - val_accuracy: 0.7964 - val_loss: 0.5233 - learning_rate: 5.0000e-06\n",
            "Epoch 10/40\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635ms/step - accuracy: 0.9235 - loss: 0.2038\n",
            "Epoch 10: val_accuracy did not improve from 0.79641\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 735ms/step - accuracy: 0.9239 - loss: 0.2036 - val_accuracy: 0.7844 - val_loss: 0.5267 - learning_rate: 5.0000e-06\n",
            "Epoch 11/40\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632ms/step - accuracy: 0.9263 - loss: 0.1964\n",
            "Epoch 11: val_accuracy did not improve from 0.79641\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 733ms/step - accuracy: 0.9268 - loss: 0.1961 - val_accuracy: 0.7844 - val_loss: 0.5275 - learning_rate: 5.0000e-06\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79fdc031a050>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ارزیابی نهایی"
      ],
      "metadata": {
        "id": "SdxHArIYrJ9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"best_resnet50.h5\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "print(f\"\\n✅ دقت نهایی روی تست: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WFsgJIslZqo",
        "outputId": "176077ed-b7d6-4f8e-b16e-da4330431fd0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.7049 - loss: 0.6326\n",
            "\n",
            "✅ دقت نهایی روی تست: 0.7500\n"
          ]
        }
      ]
    }
  ]
}